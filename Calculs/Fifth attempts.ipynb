{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changement 5ème version\n",
    "On va modifier la pipeline d'entréee de data, on va préenregistrer les masques et les lires dans notre iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "import csv\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy as cp\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (7.0.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0-dev20200323'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Launch into docker : sudo docker run --gpus all -it -v $(realpath ~/Github/kaggle-steel-defect/Calculs/):/tf/notebooks -p 8888:8888 tensorflow/tensorflow:nightly-gpu-jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compétition Kaggle : Image segmentation pour la production d'acier"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Objectif du notebook : Charger intelligemment les données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load to memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PATHS and DIRECTORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get local variables\n",
    "local_path = os.getcwd()\n",
    "data_path = os.path.join(local_path,'data/')\n",
    "\n",
    "# data directories\n",
    "train_dir = os.path.join(data_path,'train_images/')\n",
    "validation_dir = os.path.join(data_path,'validation_images/')\n",
    "\n",
    "# csv files \n",
    "train_csv = os.path.join(data_path,'train.csv')\n",
    "validation_csv = os.path.join(data_path,'validation.csv')\n",
    "\n",
    "# mask directories\n",
    "masks_train_dir = os.path.join(data_path,'train_masks/')\n",
    "masks_validation_dir = os.path.join(data_path,'validation_masks/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonctions de conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On ne garde en mémoire que les dictionnaires contenant à la fois les descriptions des images. Ainsi, on peut charger à tous moments les masques, très gourmands en mémoire. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On créer les dictionnaires importants\n",
    "train_descriptions = CSV_to_descriptions(train_csv)\n",
    "validation_descriptions = CSV_to_descriptions(validation_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ne garde que ce qui nous intéresse\n",
    "train_names_list = train_descriptions.keys()\n",
    "validation_names_list = validation_descriptions.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0cb590f8e\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 1600, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##plot random images with their segmentations\n",
    "\n",
    "# select random image\n",
    "img_number = random.randint(0,len(train_descriptions.keys())-1)\n",
    "img_name = list(train_descriptions.keys())[img_number]\n",
    "img_name = '0cb590f8e'\n",
    "print(img_name)\n",
    "#img = mpimg.imread(os.path.join(TRAINING_DIR,img_name))\n",
    "#plot image\n",
    "description_to_image(img_name,train_descriptions,train_dir,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par une première version simplifiée. On va réduire les data_sets pour réduire le poids en mémoire. De plus on va uniquement programmer en CPU. Les améliorations se succèderont ensuite. \n",
    "Images : $256\\times1600\\times3$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 1600, 4)\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([256, 256, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = mpimg.imread(os.path.join(masks_train_dir,'ef24da2ba'+'.png'))\n",
    "img_name = 'ef24da2ba'\n",
    "print(a.shape)\n",
    "print(a.max())\n",
    "plt.imshow(a)\n",
    "img = tf.cast(np.array(mpimg.imread(os.path.join(train_dir,img_name+'.jpg'))),tf.float16)\n",
    "mask = tf.cast(np.array(mpimg.imread(os.path.join(masks_train_dir,img_name+'.png'))),tf.float16)\n",
    "img[:,1600-256:1600,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generator:\n",
    "    def __init__(self,descriptions_list,image_directory,masks_directory):\n",
    "        self.descriptions_list = descriptions_list\n",
    "        self.image_directory = image_directory\n",
    "        self.masks_directory = masks_directory\n",
    "        self.IMG_WIDTH = 256\n",
    "        self.IMG_LENGTH = 256\n",
    "        \n",
    "    def gen_series(self):\n",
    "        for img_name in self.descriptions_list:\n",
    "            img = tf.cast(np.array(mpimg.imread(os.path.join(self.image_directory,img_name+'.jpg'))),tf.float16)\n",
    "            mask = tf.cast(np.array(mpimg.imread(os.path.join(self.masks_directory,img_name+'.png'))),tf.float16)\n",
    "\n",
    "            for x0 in range(1600//256+1):\n",
    "                \n",
    "                if x0 < 1600//256:\n",
    "                    img2,mask2 = img[:,x0*256:(x0+1)*256,:],mask[:,x0*256:(x0+1)*256,:]\n",
    "                    img2,mask2 = img2/255.,mask2/255.\n",
    "                    yield img2,mask2\n",
    "                else:\n",
    "                    img2,mask2 = img[:,1600-256:1600,:],mask[:,1600-256:1600,:]\n",
    "                    img2,mask2 = img2/255.,mask2/255.\n",
    "                    yield img2,mask2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_generator = generator(train_names_list,train_dir,masks_train_dir)\n",
    "validation_generator = generator(validation_names_list,validation_dir,masks_validation_dir)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_generator(\n",
    "    train_generator.gen_series,\n",
    "    output_types = (tf.float16,tf.float16),\n",
    "    output_shapes = (tf.TensorShape([256,256,3]), tf.TensorShape([256,256,4]))\n",
    ") \n",
    "# attention validation différent de test\n",
    "validation_ds = tf.data.Dataset.from_generator(\n",
    "    validation_generator.gen_series,\n",
    "    output_types = (tf.float16,tf.float16),\n",
    "    output_shapes = (tf.TensorShape([256,256,3]), tf.TensorShape([256,256,4]))\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.batch(16)\n",
    "validation_ds = validation_ds.batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float16, name=None),\n",
       " TensorSpec(shape=(None, 256, 256, 4), dtype=tf.float16, name=None))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all layers\n",
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick(double,tolerance):\n",
    "    \"choose if 1 or 0 tolerance should be 0.5\"\n",
    "    if double > tolerance and double <=1:\n",
    "        return 1\n",
    "    elif double >=0 and double <=1:\n",
    "        return 0\n",
    "    else :\n",
    "        print('erreur dans la probabilité, voir loss ')\n",
    "        \n",
    "pick_vecteur = np.vectorize(pick,excluded = ['tolerance'])\n",
    "\n",
    "def dice_coefficient(y_true,y_pred,tolerance = 0.5 ):\n",
    "    \"metric function\"\n",
    "    \n",
    "    intersection = pick_vecteur(y_true*y_pred,tolerance)\n",
    "    intersection = 2*np.sum(intersection)\n",
    "    \n",
    "    if np.sum(y_true) == 0 and np.sum(y_pred)==0 :\n",
    "        return 1\n",
    "    else :\n",
    "        return intersection/(np.sum(y_pred)+np.sum(y_true))\n",
    "    \n",
    "def jaccard_distance(y_true, y_pred, smooth=100):\n",
    "    \"loss function\"\n",
    "    y_true_f = tf.keras.layers.Flatten()(y_true)\n",
    "    y_pred_f = tf.keras.layers.Flatten()(y_pred)\n",
    "    intersection = tf.reduce_sum((y_true * y_pred))\n",
    "    sum_ = tf.reduce_sum(y_true+y_pred)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return (1 - jac) * smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = tf.keras.layers.Flatten()(y_true)\n",
    "    y_pred_f = tf.keras.layers.Flatten()(y_pred)\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1 - dice(y_true, y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focal Tversky loss, brought to you by:  https://github.com/nabsabraham/focal-tversky-unet\n",
    "def tversky(y_true, y_pred, smooth=1e-6):\n",
    "    y_true_pos = tf.keras.layers.Flatten()(y_true)\n",
    "    y_pred_pos = tf.keras.layers.Flatten()(y_pred)\n",
    "    true_pos = tf.reduce_sum(y_true_pos * y_pred_pos)\n",
    "    false_neg = tf.reduce_sum(y_true_pos * (1-y_pred_pos))\n",
    "    false_pos = tf.reduce_sum((1-y_true_pos)*y_pred_pos)\n",
    "    alpha = 0.7\n",
    "    return (true_pos + smooth)/(true_pos + alpha*false_neg + (1-alpha)*false_pos + smooth)\n",
    "\n",
    "def tversky_loss(y_true, y_pred):\n",
    "    return 1 - tversky(y_true,y_pred)\n",
    "\n",
    "def focal_tversky_loss(y_true,y_pred):\n",
    "    pt_1 = tversky(y_true, y_pred)\n",
    "    gamma = 0.75\n",
    "    return tf.keras.backend.pow((1-pt_1), gamma)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "inputs = tf.keras.Input(shape=(3,))\n",
    "x = tf.keras.layers.Dense(4, activation=tf.nn.relu)(inputs)\n",
    "outputs = tf.keras.layers.Dense(5, activation=tf.nn.softmax)(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet(pretrained_weights = None,input_size = (256,256,3)):\n",
    "    inputs = tf.keras.Input(input_size)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(4, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv2D(4, 1, activation = 'softmax')(conv9)\n",
    "\n",
    "    model = tf.keras.Model(inputs = inputs, outputs = conv10)\n",
    "    \n",
    "    #loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "    loss_object = focal_tversky_loss\n",
    "    \n",
    "    optimizer_object = tf.keras.optimizers.Adam()\n",
    "\n",
    "    model.compile(optimizer = optimizer_object, loss = loss_object, metrics = [tversky])\n",
    "    \n",
    "    #model.summary()\n",
    "\n",
    "    if(pretrained_weights):\n",
    "    \tmodel.load_weights(pretrained_weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet()\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('unet.hdf5',monitor = 'loss', verbose =1, save_best_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 256, 256, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 64) 36928       conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 128, 128, 64) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 128 73856       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 128 147584      conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 256)  295168      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 256)  590080      conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 512)  1180160     max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 512)  2359808     conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32, 32, 512)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 512)  0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 1024) 4719616     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 1024) 9438208     conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16, 16, 1024) 0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 32, 32, 1024) 0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 512)  2097664     up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 1024) 0           dropout[0][0]                    \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 512)  4719104     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 512)  2359808     conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 512)  0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 256)  524544      up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 64, 512)  0           conv2d_5[0][0]                   \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 256)  1179904     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 256)  590080      conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 256 0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 128, 128, 128 131200      up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 128, 256 0           conv2d_3[0][0]                   \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 128 295040      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 128, 128, 128 147584      conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 128 0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 256, 256, 64) 32832       up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 256, 256, 128 0           conv2d_1[0][0]                   \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 256, 256, 64) 73792       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 256, 256, 4)  2308        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 256, 256, 4)  20          conv2d_22[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 31,034,008\n",
      "Trainable params: 31,034,008\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n",
      "    244/Unknown - 165s 677ms/step - loss: 1.0000 - tversky: 1.1895e-05"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-df0db333c88a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    851\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \"\"\"\n\u001b[1;32m    395\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m           \u001b[0mnumpy_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0mbatch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    517\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \"\"\"\n\u001b[1;32m   1087\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_ds,epochs =13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_image_name,image_directory):\n",
    "    \"predict of an image by its name\"\n",
    "    input_image = mpimg.imread(os.path.join(image_directory,input_image_name+'.jpg'))\n",
    "    input_image = np.expand_dims(input_image,axis = 0)\n",
    "    input_image = np.array(input_image,dtype = np.float32)\n",
    "    \n",
    "    output_image = np.zeros((1,256,0,4))\n",
    "    for x0 in range(1600//256):\n",
    "        \n",
    "        pred = model.predict(input_image[:,:,x0*256:(x0+1)*256,:])\n",
    "        \n",
    "        output_image = np.concatenate((output_image,pred),axis =2)\n",
    "    \n",
    "    pred = model.predict(input_image[:,:,1600-256:1600,:])\n",
    "    \n",
    "    output_image = np.concatenate((output_image,pred[:,:,256-1600%256:256,:]), axis =2)\n",
    "    \n",
    "    return output_image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = predict('ef24da2ba',train_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verif(input_image_name,image_directory,dict_descriptions):\n",
    "    \"Des verifications permettant de verifier ce que fait le predict\"\n",
    "    \n",
    "    prediction_image = predict(input_image_name,image_directory)\n",
    "    reality_image =np.expand_dims(image_to_mask_4(dict_descriptions,input_image_name),axis = 0)\n",
    "    print(prediction_image.shape,reality_image.shape)\n",
    "    print(\"somme de la prediction\" ,np.sum(prediction_image))\n",
    "    print(\"somme de la realité\", np.sum(reality_image))\n",
    "    print(\"difference des deux\", np.sum(reality_image-prediction_image))\n",
    "    \n",
    "    #rajouter ensuite pour chaque défaut\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verif('ef24da2ba',train_dir,train_descriptions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will predict this image\n",
    "\n",
    "image_directory = join(os.getcwd(),'data','train_images/')\n",
    "input_image_name = 'ef24da2ba'\n",
    "\n",
    "input_image = mpimg.imread(os.path.join(image_directory,input_image_name+'.jpg'))\n",
    "input_image = np.expand_dims(input_image,axis = 0)\n",
    "input_image = np.array(input_image,dtype = np.float32)\n",
    "input_image = input_image[:,:,0:256,:]\n",
    "pred = model.predict(input_image)\n",
    "\n",
    "pred.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
